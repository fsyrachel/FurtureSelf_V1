"""
ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•é…ç½®
éœ€è¦çœŸå®çš„ Redis å’Œ Celery Worker ç¯å¢ƒ
"""
import pytest
import time
import uuid
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from fastapi.testclient import TestClient

from app.main import app
from app.core.database import Base
from app.core.config import settings
from app.models import User


# é›†æˆæµ‹è¯•ä½¿ç”¨çœŸå®çš„Rediså’Œæ•°æ®åº“
INTEGRATION_DATABASE_URL = settings.DATABASE_URL.replace("futureself_db", "futureself_test_integration")

def ensure_integration_database_exists():
    """
    ç¡®ä¿é›†æˆæµ‹è¯•æ•°æ®åº“å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºå®ƒ
    """
    import psycopg2
    from psycopg2 import sql
    from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
    
    # ä» DATABASE_URL è§£æè¿æ¥å‚æ•°
    # æ ¼å¼: postgresql+psycopg2://user:password@host:port/dbname
    import re
    match = re.match(r'postgresql\+psycopg2://([^:]+):([^@]+)@([^:]+):(\d+)/(.+)', settings.DATABASE_URL)
    if not match:
        raise ValueError(f"æ— æ³•è§£æ DATABASE_URL: {settings.DATABASE_URL}")
    
    user, password, host, port, _ = match.groups()
    test_db_name = "futureself_test_integration"
    
    # è¿æ¥åˆ°é»˜è®¤çš„ postgres æ•°æ®åº“
    try:
        conn = psycopg2.connect(
            dbname="postgres",
            user=user,
            password=password,
            host=host,
            port=port
        )
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        cursor = conn.cursor()
        
        # æ£€æŸ¥æµ‹è¯•æ•°æ®åº“æ˜¯å¦å­˜åœ¨
        cursor.execute(
            "SELECT 1 FROM pg_database WHERE datname = %s",
            (test_db_name,)
        )
        
        if not cursor.fetchone():
            # æ•°æ®åº“ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
            print(f"ğŸ“ åˆ›å»ºé›†æˆæµ‹è¯•æ•°æ®åº“: {test_db_name}")
            cursor.execute(
                sql.SQL("CREATE DATABASE {}").format(
                    sql.Identifier(test_db_name)
                )
            )
            print(f"âœ… æ•°æ®åº“ {test_db_name} åˆ›å»ºæˆåŠŸ")
            
            # è¿æ¥åˆ°æ–°åˆ›å»ºçš„æ•°æ®åº“å¹¶å¯ç”¨å¿…è¦çš„æ‰©å±•
            conn.close()
            conn = psycopg2.connect(
                dbname=test_db_name,
                user=user,
                password=password,
                host=host,
                port=port
            )
            conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
            cursor = conn.cursor()
            
            # å¯ç”¨ pgvector å’Œ uuid-ossp æ‰©å±•
            print(f"ğŸ“ å¯ç”¨ PostgreSQL æ‰©å±•...")
            cursor.execute("CREATE EXTENSION IF NOT EXISTS vector")
            cursor.execute("CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\"")
            print(f"âœ… æ‰©å±•å¯ç”¨æˆåŠŸ")
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºé›†æˆæµ‹è¯•æ•°æ®åº“å¤±è´¥: {e}")
        print(f"ğŸ’¡ è¯·æ‰‹åŠ¨åˆ›å»ºæ•°æ®åº“:")
        print(f"   createdb -U {user} {test_db_name}")
        print(f"   psql -U {user} -d {test_db_name} -c 'CREATE EXTENSION IF NOT EXISTS vector'")
        print(f"   psql -U {user} -d {test_db_name} -c 'CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\"'")
        raise


@pytest.fixture(scope="session")
def integration_engine():
    """åˆ›å»ºé›†æˆæµ‹è¯•æ•°æ®åº“å¼•æ“"""
    # ç¡®ä¿æ•°æ®åº“å­˜åœ¨
    ensure_integration_database_exists()
    
    engine = create_engine(INTEGRATION_DATABASE_URL)
    Base.metadata.create_all(bind=engine)
    yield engine
    Base.metadata.drop_all(bind=engine)


@pytest.fixture(scope="function")
def integration_db_session(integration_engine):
    """æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯"""
    Session = sessionmaker(bind=integration_engine)
    session = Session()
    yield session
    
    # æ¸…ç†æ‰€æœ‰è¡¨æ•°æ®
    for table in reversed(Base.metadata.sorted_tables):
        session.execute(table.delete())
    session.commit()
    session.close()


@pytest.fixture()
def integration_test_user(integration_db_session):
    """åˆ›å»ºé›†æˆæµ‹è¯•ç”¨æˆ·"""
    user = User(id=uuid.uuid4(), status="ACTIVE")
    integration_db_session.add(user)
    integration_db_session.commit()
    integration_db_session.refresh(user)
    return user


@pytest.fixture()
def integration_client(integration_db_session, integration_test_user):
    """é›†æˆæµ‹è¯•å®¢æˆ·ç«¯ - ä½¿ç”¨çœŸå®çš„ä¾èµ–ï¼ˆä¸mockï¼‰"""
    from app.dependencies import get_db, get_current_user
    
    def override_get_db():
        try:
            yield integration_db_session
        finally:
            pass
    
    async def override_get_current_user():
        return integration_test_user
    
    app.dependency_overrides[get_db] = override_get_db
    app.dependency_overrides[get_current_user] = override_get_current_user
    
    with TestClient(app) as client:
        yield client
    
    app.dependency_overrides.clear()


def wait_for_task_completion(db_session, model, record_id, status_field="status", 
                             expected_status="READY", timeout=60, poll_interval=2):
    """
    è½®è¯¢ç­‰å¾…å¼‚æ­¥ä»»åŠ¡å®Œæˆ
    
    Args:
        db_session: æ•°æ®åº“ä¼šè¯
        model: æ¨¡å‹ç±»ï¼ˆå¦‚ Letter, Reportï¼‰
        record_id: è®°å½•ID
        status_field: çŠ¶æ€å­—æ®µå
        expected_status: æœŸæœ›çš„æœ€ç»ˆçŠ¶æ€
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        poll_interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
    
    Returns:
        è®°å½•å¯¹è±¡ï¼Œå¦‚æœè¶…æ—¶åˆ™è¿”å› None
    """
    start_time = time.time()
    
    while time.time() - start_time < timeout:
        db_session.expire_all()  # åˆ·æ–°ä¼šè¯ï¼Œè·å–æœ€æ–°æ•°æ®
        record = db_session.query(model).filter(model.id == record_id).first()
        
        if record is None:
            return None
        
        current_status = getattr(record, status_field)
        
        if current_status == expected_status:
            return record
        
        if current_status == "FAILED":
            return record  # è¿”å›å¤±è´¥çš„è®°å½•ï¼Œè®©æµ‹è¯•æ–­è¨€å¤±è´¥
        
        time.sleep(poll_interval)
    
    return None  # è¶…æ—¶

